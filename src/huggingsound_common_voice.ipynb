{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from evaluate import load\n",
    "from datasets import load_from_disk\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str):\n",
    "    for char in [\".\", \",\", \"!\", \"?\", \"(\", \")\"]:\n",
    "        text = text.replace(char , \" \")\n",
    "    text = text.replace(\"ё\", \"е\")\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    text = text.lower().strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = \"jonatasgrosman/wav2vec2-xls-r-1b-russian\"\n",
    "# MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-russian\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vad_0.4', 'vad_0.3', 'vad_orig', 'vad_0.1', 'vad_0.0', 'vad_0.5', 'vad_0.2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basefolder = \"/home/docker_current/src/common_voice\"\n",
    "folders = os.listdir(basefolder)\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vad_0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [02:35<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer = 15.429159696306783, cer = 5.122633309398738\n",
      "vad_0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [02:26<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer = 15.712263543945436, cer = 5.364498696194399\n",
      "vad_orig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:38<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer = 15.019255455712452, cer = 4.742151409446592\n",
      "vad_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [02:08<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer = 17.732595547548577, cer = 7.503495710668531\n",
      "vad_0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [02:00<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer = 20.113241539055462, cer = 9.965609765314992\n",
      "vad_0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [02:23<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer = 15.094582421824734, cer = 4.869430482597029\n",
      "vad_0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [02:12<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer = 16.40715480633123, cer = 6.192131816635803\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    print(folder)\n",
    "\n",
    "    common_voice = load_from_disk(os.path.join(basefolder, folder))\n",
    "\n",
    "    preds = []\n",
    "    refs = []\n",
    "\n",
    "    for i in tqdm(range(len(common_voice))):\n",
    "        wav = wav = torch.Tensor(common_voice[i][\"audio\"][\"array\"])\n",
    "        gt = common_voice[i][\"sentence\"]\n",
    "\n",
    "        # get pred by model\n",
    "        inputs = processor(wav, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "        preds += predicted_sentences\n",
    "        refs.append(gt)\n",
    "        \n",
    "    preds = [normalize_text(i) for i in preds]\n",
    "    refs = [normalize_text(i) for i in refs]\n",
    "\n",
    "    wer_metric = 100 * wer.compute(predictions=preds, references=refs)\n",
    "    cer_metric = 100 * cer.compute(predictions=preds, references=refs)\n",
    "    print(f\"wer = {wer_metric}, cer = {cer_metric}\")\n",
    "    \n",
    "    data = {\"reserve\" : folder.replace(\".\", \"_\"),\n",
    "            \"dataset\" : \"common_voice\",\n",
    "            \"wer\" : wer_metric,\n",
    "            \"cer\" : cer_metric}\n",
    "    \n",
    "    data = pd.DataFrame([data])\n",
    "    df = pd.concat([df, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/docker_current/src/metrics/huggingsound_commonvoice.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
